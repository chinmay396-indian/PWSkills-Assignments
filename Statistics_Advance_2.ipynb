{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHdmnXSaD1TLe9labycNAy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chinmay396-indian/PWSkills-Assignments/blob/main/Statistics_Advance_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWmwONpAfx8-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
        "an example."
      ],
      "metadata": {
        "id": "RL-OmE-2f21m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probability Mass Function (PMF) and Probability Density Function (PDF) are both functions that describe the probability distribution of a random variable.\n",
        "\n",
        "A Probability Mass Function (PMF) is a function that gives the probability of each possible outcome for a discrete random variable. It assigns a probability value to each possible outcome, and the sum of all these probabilities is equal to 1. The PMF is used to calculate probabilities of specific outcomes for a discrete random variable. For example, the PMF of a fair six-sided die would give a probability of 1/6 to each possible outcome of rolling the die (1, 2, 3, 4, 5, or 6).\n",
        "\n",
        "On the other hand, a Probability Density Function (PDF) is a function that gives the relative likelihood of a continuous random variable taking on a specific value. The PDF is not a probability itself, but rather a measure of the likelihood of a certain value occurring. The area under the PDF curve represents the probability of the variable being within a certain range. For example, the PDF of the standard normal distribution describes the relative likelihood of a value occurring in a normally distributed random variable with mean 0 and standard deviation 1.\n",
        "\n",
        "Here is an example of a PMF and a PDF for two different random variables:\n",
        "\n",
        "Example of a PMF: A fair coin toss can be modeled as a Bernoulli random variable, which takes on the value 1 with probability p (the probability of heads) and the value 0 with probability 1-p (the probability of tails). The PMF of a fair coin toss would be:\n",
        "P(X=0) = 1/2\n",
        "P(X=1) = 1/2\n",
        "\n",
        "This PMF shows that the probability of getting heads (1) or tails (0) on a fair coin toss is equal, at 1/2.\n",
        "\n",
        "Example of a PDF: The height of adult humans can be modeled as a continuous random variable. A PDF that approximates the distribution of human heights might look like a normal distribution with a mean of 68 inches and a standard deviation of 3 inches. The PDF would be:\n",
        "f(x) = (1 / (3 * sqrt(2 * pi))) * exp(-((x-68)^2) / (2 * (3^2)))\n",
        "\n",
        "This PDF describes the relative likelihood of a person being a certain height, with higher probabilities around the mean height of 68 inches and lower probabilities as the distance from the mean increases."
      ],
      "metadata": {
        "id": "T9A7li6Kf49b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
      ],
      "metadata": {
        "id": "gyiSHM6if7AI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Cumulative Density Function (CDF) is a mathematical concept used in probability theory to describe the cumulative probability of a random variable X being less than or equal to a certain value x.\n",
        "\n",
        "In other words, the CDF of a random variable X, denoted as F(x), gives the probability that X is less than or equal to x, as x ranges over all possible values.\n",
        "\n",
        "Mathematically, the CDF is expressed as:\n",
        "\n",
        "F(x) = P(X ≤ x)\n",
        "\n",
        "where P(X ≤ x) is the probability that X is less than or equal to x.\n",
        "\n",
        "For example, let's consider a simple scenario where a fair six-sided die is rolled. In this case, the CDF can be represented as:\n",
        "\n",
        "x\t1\t2\t3\t4\t5\t6\n",
        "F(x)\t1/6\t2/6\t3/6\t4/6\t5/6\t1\n",
        "Here, the first column represents the possible values of the random variable X (the face of the die), and the second column represents the corresponding cumulative probabilities (i.e., the probability of rolling a value less than or equal to the given value).\n",
        "\n",
        "The CDF is used to determine several important statistics, such as the mean, median, and mode, which can provide insights into the distribution of the random variable. It is also used to calculate the probability of certain events, such as the probability of X falling within a certain range.\n",
        "\n",
        "Overall, the CDF is an important concept in probability theory and statistics, as it provides a way to characterize and analyze the behavior of random variables."
      ],
      "metadata": {
        "id": "vJX_7gprgZuj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
        "Explain how the parameters of the normal distribution relate to the shape of the distribution."
      ],
      "metadata": {
        "id": "zQmVDsaNgbLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The normal distribution, also known as the Gaussian distribution, is a commonly used probability distribution in statistics. It is a continuous probability distribution that is often used as a model to describe the distribution of real-world phenomena.\n",
        "\n",
        "Here are some examples of situations where the normal distribution might be used as a model:\n",
        "\n",
        "Heights of people in a population\n",
        "Weights of objects produced by a manufacturing process\n",
        "Test scores of a large group of students\n",
        "IQ scores of a population\n",
        "Blood pressure readings of a population\n",
        "Amount of rainfall in a region over a period of time\n",
        "The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean represents the central tendency of the distribution and determines the location of the peak. The standard deviation represents the spread of the distribution and determines the width of the curve.\n",
        "\n",
        "If the mean is shifted to the right, the curve will shift to the right as well, while if the mean is shifted to the left, the curve will shift to the left. Similarly, if the standard deviation is increased, the curve will become wider, while if the standard deviation is decreased, the curve will become narrower.\n",
        "\n",
        "In general, the normal distribution is symmetric, with a bell-shaped curve, where the majority of the values cluster around the mean. Specifically, the area under the curve between the mean minus one standard deviation and the mean plus one standard deviation contains about 68% of the data, while the area between the mean minus two standard deviations and the mean plus two standard deviations contains about 95% of the data. This makes the normal distribution a convenient model for many real-world phenomena where the majority of the values cluster around a central value and the spread of the data is known or can be estimated."
      ],
      "metadata": {
        "id": "TZFm6I1Rohqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
        "Distribution."
      ],
      "metadata": {
        "id": "FFcMCyoAjm5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normal distribution, also known as Gaussian distribution or the bell curve, is a statistical distribution that is widely used in many fields, including mathematics, physics, engineering, and social sciences. It is important because it describes the distribution of many natural phenomena in the world around us.\n",
        "\n",
        "One of the main reasons normal distribution is important is because it is the basis for many statistical techniques and models. Normal distribution is a continuous probability distribution that is symmetric, meaning that the probability density function is the same on both sides of the mean. This makes it a useful tool for estimating the probability of an event occurring, given a set of data.\n",
        "\n",
        "Some real-life examples of normal distribution include:\n",
        "\n",
        "Heights of a population: The heights of individuals within a population often follow a normal distribution, with most people being around the average height and fewer people being much taller or shorter.\n",
        "\n",
        "IQ scores: IQ scores also tend to follow a normal distribution, with most people having average intelligence and fewer people having very high or very low intelligence.\n",
        "\n",
        "Blood pressure: Blood pressure measurements often follow a normal distribution, with most people having a blood pressure close to the average and fewer people having very high or very low blood pressure.\n",
        "\n",
        "Test scores: Test scores in many educational settings also follow a normal distribution, with most students scoring around the average and fewer students scoring very high or very low.\n",
        "\n",
        "In all of these examples, the normal distribution is important because it allows us to make predictions and estimates about the likelihood of certain events occurring, based on the data we have available. It is a useful tool for analyzing and interpreting data in a wide range of fields."
      ],
      "metadata": {
        "id": "ntEouBFyjnwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
        "Distribution and Binomial Distribution?"
      ],
      "metadata": {
        "id": "CniWasndkKsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bernoulli distribution is a discrete probability distribution that represents the outcome of a single binary event (i.e., an event that can only have two possible outcomes, such as success or failure). It is named after the Swiss mathematician Jacob Bernoulli, who first introduced it in his book Ars Conjectandi in 1713.\n",
        "\n",
        "The Bernoulli distribution is characterized by a single parameter p, which represents the probability of success in a single trial. The probability of failure is equal to 1-p. The Bernoulli distribution is often used in situations where we are interested in the probability of a single event occurring or not occurring.\n",
        "\n",
        "An example of Bernoulli distribution is tossing a coin. The outcome of each toss can only be either heads or tails, so it is a binary event. The probability of getting heads (success) is p=0.5, and the probability of getting tails (failure) is 1-p=0.5.\n",
        "\n",
        "The main difference between Bernoulli distribution and Binomial distribution is that the former is used to model a single binary event, while the latter is used to model the number of successes in a fixed number of independent Bernoulli trials.\n",
        "\n",
        "In other words, Binomial distribution is the distribution of the number of successes in a fixed number of independent Bernoulli trials. It is characterized by two parameters: n, which represents the number of trials, and p, which represents the probability of success in a single trial. The Binomial distribution is often used in situations where we are interested in the probability of a certain number of successes occurring in a fixed number of independent trials.\n",
        "\n",
        "An example of Binomial distribution is flipping a coin 10 times and counting the number of times it lands on heads. Each toss is a Bernoulli trial, and the number of heads is a Binomial random variable.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P02ZgNhNkOlp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
        "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
        "than 60? Use the appropriate formula and show your calculations.\n"
      ],
      "metadata": {
        "id": "OJ5y08JjkuMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To solve this problem, we need to use the standard normal distribution and find the area under the curve to the right of the value x = 60. We can do this by converting the value 60 to a z-score using the formula:\n",
        "\n",
        "z = (x - μ) / σ\n",
        "\n",
        "where x is the value we want to convert, μ is the mean of the distribution, and σ is the standard deviation of the distribution.\n",
        "\n",
        "Substituting the given values, we get:\n",
        "\n",
        "z = (60 - 50) / 10\n",
        "z = 1\n",
        "\n",
        "Now we need to find the area under the standard normal distribution curve to the right of z = 1. We can look this up in a standard normal distribution table or use a calculator. Using a calculator, we can use the normal distribution function with a mean of 0 and a standard deviation of 1 to find the probability:\n",
        "\n",
        "P(Z > 1) = 1 - P(Z < 1)\n",
        "P(Z > 1) = 1 - 0.8413 (from a standard normal distribution table)\n",
        "P(Z > 1) = 0.1587\n",
        "\n",
        "Therefore, the probability that a randomly selected observation from the given dataset will be greater than 60 is approximately 0.1587 or 15.87%."
      ],
      "metadata": {
        "id": "q4hLkmCRk6kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7: Explain uniform Distribution with an example."
      ],
      "metadata": {
        "id": "Th5PoiTnmLMk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uniform distribution is a continuous probability distribution that describes a situation where all values within a certain range are equally likely to occur. In other words, a uniform distribution is characterized by a constant probability density function (PDF) within a specified interval.\n",
        "\n",
        "For example, consider the situation where a fair die is rolled. The die has six sides, numbered 1 to 6, and each side is equally likely to land face-up. The probability of rolling any particular number is 1/6, which is the same for all numbers. Therefore, the distribution of the roll of a fair die follows a uniform distribution.\n",
        "\n",
        "The probability density function of a uniform distribution is given by:\n",
        "\n",
        "f(x) = 1/(b-a), for a ≤ x ≤ b\n",
        "where a and b are the lower and upper bounds of the interval.\n",
        "\n",
        "For example, if we have a uniform distribution with a lower bound of 0 and an upper bound of 10, the probability of getting a value between 2 and 7 is the same as the probability of getting a value between 5 and 9, and so on. The PDF is a horizontal line with a height of 1/10 over the interval [0,10].\n",
        "\n",
        "Uniform distributions are used in various fields, including finance, economics, and physics. In finance, for example, the return on a stock may be modeled using a uniform distribution if it is believed that the return is equally likely to fall within a certain range. In physics, the distribution of particles over a particular energy range may follow a uniform distribution if all energies within the range are equally likely."
      ],
      "metadata": {
        "id": "LzljxIZqmN0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8: What is the z score? State the importance of the z score."
      ],
      "metadata": {
        "id": "OIydflIZrlr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In statistics, the z-score (also known as the standard score or normal deviate) is a measure of how many standard deviations a data point is away from the mean of a distribution. It is calculated using the formula:\n",
        "\n",
        "z = (x - μ) / σ\n",
        "\n",
        "where x is the data point, μ is the mean of the distribution, and σ is the standard deviation of the distribution.\n",
        "\n",
        "The z-score is important because it allows us to compare data points from different distributions on a standardized scale. By standardizing the data using the z-score, we can compare data points that have different units or scales.\n",
        "\n",
        "Additionally, the z-score can be used to calculate probabilities and percentiles for a normal distribution. The area under the standard normal distribution curve to the left of a given z-score represents the proportion of data points that are less than or equal to that value. The area to the right of the z-score represents the proportion of data points that are greater than or equal to that value.\n",
        "\n",
        "The z-score is also used in hypothesis testing to determine the statistical significance of a sample mean. If the sample mean is significantly different from the population mean (as indicated by a z-score that falls in the rejection region of the standard normal distribution), then we can reject the null hypothesis and conclude that the sample mean is statistically different from the population mean.\n",
        "\n",
        "Overall, the z-score is an important tool in statistics for standardizing data, comparing data points from different distributions, and making inferences about a population based on a sample."
      ],
      "metadata": {
        "id": "1lHv7-Evtf-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
      ],
      "metadata": {
        "id": "Qgj53YivuT06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the behavior of sample means or sample sums for a large number of independent, identically distributed random variables. It states that as the sample size increases, the distribution of the sample mean (or sum) will approach a normal distribution, regardless of the underlying distribution of the individual observations.\n",
        "\n",
        "In other words, if we take many random samples of the same size from any population with any distribution (even if the distribution is not normal), the sampling distribution of the means or sums will be approximately normal as the sample size increases. The mean of the sampling distribution will be equal to the population mean, and the standard deviation of the sampling distribution will be equal to the population standard deviation divided by the square root of the sample size.\n",
        "\n",
        "The significance of the Central Limit Theorem is that it allows us to make inferences about the population mean or sum based on a sample mean or sum, even if the population distribution is unknown or non-normal. This is because the normal distribution is well understood, and many statistical tests and confidence intervals are based on the assumption of a normal distribution.\n",
        "\n",
        "The CLT is used extensively in hypothesis testing, confidence intervals, and estimation, particularly when dealing with large sample sizes. It also has practical applications in many fields, including economics, engineering, and social sciences, where it is often necessary to make inferences about a population based on a sample."
      ],
      "metadata": {
        "id": "KzofwzKHvwXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10: State the assumptions of the Central Limit Theorem.\n"
      ],
      "metadata": {
        "id": "QEPn6eAJv4L4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that the sampling distribution of the sample means or sample sums of a large number of independent, identically distributed random variables approaches a normal distribution, regardless of the underlying distribution of the individual observations. However, this theorem comes with certain assumptions that must be met for it to be applicable. These assumptions include:\n",
        "\n",
        "Independence: The observations must be independent of each other. In other words, the outcome of one observation must not influence the outcome of any other observation.\n",
        "\n",
        "Sample size: The sample size must be large enough. A rule of thumb is that the sample size should be at least 30, but in some cases, a smaller sample size may suffice.\n",
        "\n",
        "Random sampling: The observations must be selected at random from the population of interest.\n",
        "\n",
        "Finite variance: The population from which the sample is drawn must have a finite variance. This means that the variance of the population must be a finite number.\n",
        "\n",
        "If these assumptions are met, then the Central Limit Theorem can be used to make inferences about the population mean or sum based on a sample mean or sum, even if the population distribution is unknown or non-normal. However, if any of these assumptions are violated, then the CLT may not hold, and alternative methods of statistical analysis may be required."
      ],
      "metadata": {
        "id": "2ILwZWKtv77-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Bh9syjM_okJv"
      }
    }
  ]
}